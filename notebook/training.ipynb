{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gpu\n",
    "print(tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    "))\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv(\"data-P1.csv\")\n",
    "dftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = pd.read_csv(\"data-P2.csv\")\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_train = dftrain[dftrain.isna().any(axis=1)][\"timestep\"].unique()  # dealing with missing data\n",
    "\n",
    "train_set = dftrain[~dftrain.timestep.isin(missing_train)]\n",
    "    \n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_test = dftest[dftest.isna().any(axis=1)][\"timestep\"].unique()  # dealing with missing data\n",
    "\n",
    "test_set = dftest[~dftest.timestep.isin(missing_test)]\n",
    "\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_network_in(df: pd.DataFrame, target_present: bool = True):\n",
    "\n",
    "    n_catch = df[\"code\"].unique().size\n",
    "\n",
    "    # % Drop info columns\n",
    "    df = df.drop([\"code\", \"timestep\"], axis=1)  \n",
    "\n",
    "    if target_present:\n",
    "        # check if 'bias' is already the last column\n",
    "        if df.columns[-1] != \"bias\":\n",
    "            columns = [col for col in df.columns if col != \"bias\"]\n",
    "            columns.append(\"bias\")\n",
    "            df = df[columns]\n",
    "        \n",
    "        # convert to numpy array\n",
    "        data = df.to_numpy()[..., :-1]\n",
    "        target = df.to_numpy()[..., -1]\n",
    "        target = target.reshape(-1, n_catch)\n",
    "\n",
    "    else:\n",
    "        data = df.to_numpy()\n",
    "        target = None\n",
    "\n",
    "    # % Normalize\n",
    "    data = RobustScaler().fit_transform(data) \n",
    "    data = data.reshape(-1, n_catch, data.shape[-1])\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, target = df_to_network_in(train_set)\n",
    "\n",
    "train.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, target_test = df_to_network_in(test_set)\n",
    "\n",
    "test.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_net(input_shape):\n",
    "\n",
    "    net = tf.keras.Sequential()\n",
    "\n",
    "    net.add(Bidirectional(LSTM(64, input_shape=input_shape, return_sequences=True)))\n",
    "    net.add(Dropout(0.2))\n",
    "    net.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    net.add(Dropout(0.2))\n",
    "    net.add(Dense(16, activation='selu'))\n",
    "    net.add(Dense(1))\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 200\n",
    "BATCH_SIZE = 512\n",
    "K_FOLD = 5\n",
    "\n",
    "net_path = \"nets/net\"\n",
    "test_preds = []\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nse_loss(y_true, y_pred):\n",
    "#     numerator = tf.reduce_sum((y_true - y_pred)**2)\n",
    "#     denominator = tf.reduce_sum((y_true - tf.reduce_mean(y_true))**2)\n",
    "#     return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():    \n",
    "    \n",
    "    kf = KFold(n_splits=K_FOLD, shuffle=True)\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, target)):  # Cross Validation Training\n",
    "\n",
    "        print(f'</> Training Fold {fold + 1}...')\n",
    "\n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = target[train_idx], target[test_idx]\n",
    "\n",
    "        net = lstm_net(train.shape[-2:])\n",
    "        net.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "        scheduler = ExponentialDecay(1e-3, 100*((train.shape[0]*0.8)/BATCH_SIZE), 1e-5)\n",
    "        lr = LearningRateScheduler(scheduler)\n",
    "        \n",
    "        cp = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f\"{net_path}_fold{fold + 1}\",\n",
    "            save_weights_only=True,\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "    \n",
    "        history.append(net.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr,cp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hist in history:\n",
    "    tl = hist.history[\"loss\"]\n",
    "    vl = hist.history[\"val_loss\"]\n",
    "    plt.plot(range(len(tl)), tl, vl)\n",
    "    # plt.ylim([0,5])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = []\n",
    "for fold in range(K_FOLD):\n",
    "    net = lstm_net(train.shape[-2:])\n",
    "    net.load_weights(f\"{net_path}_fold{fold + 1}\")\n",
    "    nets.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = np.mean([net.predict(train) for net in nets], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(ypred.size),target.flatten(), ypred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loss in [mean_absolute_error, mean_squared_error]:\n",
    "    print(f\"{loss.__name__}: not corrected {loss(np.zeros(target.flatten().shape),target.flatten())}, corrected {loss(ypred.flatten(),target.flatten())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = pd.DataFrame({\"code\": train_set[\"code\"], \"timestep\": train_set[\"timestep\"], \"bias\": ypred.flatten()})\n",
    "df_correct.to_csv(\"data-corrected-P1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_test = np.mean([net.predict(test) for net in nets], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(ypred_test.size),target_test.flatten(), ypred_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loss in [mean_absolute_error, mean_squared_error]:\n",
    "    print(f\"{loss.__name__}: not corrected {loss(np.zeros(target_test.flatten().shape),target_test.flatten())}, corrected {loss(ypred_test.flatten(),target_test.flatten())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = pd.DataFrame({\"code\": test_set[\"code\"], \"timestep\": test_set[\"timestep\"], \"bias\": ypred_test.flatten()})\n",
    "df_correct.to_csv(\"data-corrected-P2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smash-deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
